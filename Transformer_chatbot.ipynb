{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masterjun12/NLP_study/blob/main/Transformer_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac0e9676",
      "metadata": {
        "id": "ac0e9676",
        "outputId": "4e9d4cd6-27eb-4020-92ce-c9a6d8f48d6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-11-28 03:18:45.342086: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re, time, urllib.request\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edc4da9d",
      "metadata": {
        "id": "edc4da9d",
        "outputId": "83bf965c-ccee-4bea-c3e8-8fa8ba07714d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n",
        "     filename=\"ChatBotData.csv\")\n",
        "train_data = pd.read_csv('ChatBotData.csv')\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dabeb076",
      "metadata": {
        "id": "dabeb076",
        "outputId": "911c4924-ace2-4648-9481-e7d63a23bc08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "챗봇 샘플의 개수 : 11823\n"
          ]
        }
      ],
      "source": [
        "print('챗봇 샘플의 개수 :', len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8d3c39e",
      "metadata": {
        "id": "e8d3c39e",
        "outputId": "1efde108-407f-4092-c7c1-63de2fc89a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q        0\n",
            "A        0\n",
            "label    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc5a1b06",
      "metadata": {
        "id": "bc5a1b06"
      },
      "outputs": [],
      "source": [
        "questions, answers = [], []\n",
        "for sentence in train_data['Q']:    # 구두점에 대해서 띄어쓰기\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    questions.append(sentence)\n",
        "\n",
        "for sentence in train_data['A']:    # 구두점에 대해서 띄어쓰기\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    answers.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9793f16",
      "metadata": {
        "id": "e9793f16",
        "outputId": "be803726-e4ca-42b4-9d80-1a26e636f204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
            "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
          ]
        }
      ],
      "source": [
        "print(questions[:5])\n",
        "print(answers[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "888fab85",
      "metadata": {
        "id": "888fab85"
      },
      "outputs": [],
      "source": [
        "# Subword text encoder를 사용하여 질문, 답변 데이터로부터 단어 집합 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers,\n",
        "                                                                      target_vocab_size=2**13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5478c5b9",
      "metadata": {
        "id": "5478c5b9",
        "outputId": "96992b1b-12d0-424f-e991-2f4b1b14b0a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "시작 토큰 번호 : [8178] ('종료 토큰 번호 :', [8179])\n"
          ]
        }
      ],
      "source": [
        "# 시작 토큰과 종료 토큰에 대한 정수 부여\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "\n",
        "print('시작 토큰 번호 :',START_TOKEN, ('종료 토큰 번호 :', END_TOKEN))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b5c98df",
      "metadata": {
        "id": "5b5c98df"
      },
      "outputs": [],
      "source": [
        "# 최대 길이를 40으로 정의\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "    tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "        # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
        "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "        tokenized_inputs.append(sentence1)\n",
        "        tokenized_outputs.append(sentence2)\n",
        "    # 패딩\n",
        "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "    return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "questions, answers = tokenize_and_filter(questions, answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74334631",
      "metadata": {
        "id": "74334631",
        "outputId": "ab831d82-99f6-460a-b021-5a0b17dc5e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "질문 데이터의 크기(shape) : (11823, 40)\n",
            "답변 데이터의 크기(shape) : (11823, 40)\n"
          ]
        }
      ],
      "source": [
        "print('질문 데이터의 크기(shape) :', questions.shape)\n",
        "print('답변 데이터의 크기(shape) :', answers.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74986dd7",
      "metadata": {
        "id": "74986dd7",
        "outputId": "7263cffe-0b0f-4b51-a95b-a5c8cf85e6b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "# 0번 샘플을 임의로 출력\n",
        "print(questions[0])\n",
        "print(answers[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d62cebb",
      "metadata": {
        "id": "7d62cebb",
        "outputId": "08f9580a-1ad2-405c-9114-27e060325583"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 03:18:58.634469: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2023-11-28 03:18:58.708188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:65:00.0 name: NVIDIA A100 80GB PCIe computeCapability: 8.0\n",
            "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 79.15GiB deviceMemoryBandwidth: 1.76TiB/s\n",
            "2023-11-28 03:18:58.709425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
            "pciBusID: 0000:b3:00.0 name: NVIDIA A100 80GB PCIe computeCapability: 8.0\n",
            "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 79.15GiB deviceMemoryBandwidth: 1.76TiB/s\n",
            "2023-11-28 03:18:58.709485: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2023-11-28 03:18:58.732804: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2023-11-28 03:18:58.732910: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2023-11-28 03:18:58.735511: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2023-11-28 03:18:58.735818: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2023-11-28 03:18:58.736338: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
            "2023-11-28 03:18:58.737057: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2023-11-28 03:18:58.737228: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2023-11-28 03:18:58.742588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
            "2023-11-28 03:18:58.743288: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-28 03:18:59.179291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:65:00.0 name: NVIDIA A100 80GB PCIe computeCapability: 8.0\n",
            "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 79.15GiB deviceMemoryBandwidth: 1.76TiB/s\n",
            "2023-11-28 03:18:59.180410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
            "pciBusID: 0000:b3:00.0 name: NVIDIA A100 80GB PCIe computeCapability: 8.0\n",
            "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 79.15GiB deviceMemoryBandwidth: 1.76TiB/s\n",
            "2023-11-28 03:18:59.184744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
            "2023-11-28 03:18:59.184809: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2023-11-28 03:19:00.332929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2023-11-28 03:19:00.332963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 \n",
            "2023-11-28 03:19:00.332970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N Y \n",
            "2023-11-28 03:19:00.332974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   Y N \n",
            "2023-11-28 03:19:00.340012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 42486 MB memory) -> physical GPU (device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:65:00.0, compute capability: 8.0)\n",
            "2023-11-28 03:19:00.341789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 60838 MB memory) -> physical GPU (device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:b3:00.0, compute capability: 8.0)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "TF dataset을 이용하여 shuffle을 수행하되, 배치 크기로 데이터를 묶는다.\n",
        "또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과\n",
        "실제값 시퀀스를 구성한다.\n",
        "'''\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거\n",
        "dataset = tf.data.Dataset.from_tensor_slices(({\n",
        "    'inputs': questions,\n",
        "    'dec_inputs': answers[:, :-1]}, # 디코더의 입력. 마지막 패딩 토큰 제거\n",
        "    {'outputs': answers[:, 1:]},    # 맨 처음 시작 토큰 제거\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a96f7c4",
      "metadata": {
        "scrolled": true,
        "id": "1a96f7c4",
        "outputId": "5dccc0eb-2605-4b14-9a85-b06560058c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n",
            "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ],
      "source": [
        "print(answers[0]) # 기존 샘플\n",
        "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39 임\n",
        "print(answers[:1][:, 1:]) # 맨 처음 시작토큰이 제거되면서 길이는 역시 39가 됨"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dcb9f30",
      "metadata": {
        "id": "0dcb9f30"
      },
      "source": [
        "## PositionalEncoding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f98d2eb",
      "metadata": {
        "id": "6f98d2eb"
      },
      "source": [
        "![image-2.png](attachment:image-2.png)\n",
        "![image.png](attachment:image.png)\n",
        "from https://mltalks.medium.com/rotary-embeddings%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-8215471d1f4f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a17eddea",
      "metadata": {
        "id": "a17eddea"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    \"\"\"\n",
        "    parameter:\n",
        "    position (int): vecabulary size\n",
        "    d_model (int): embedding size\n",
        "\n",
        "    return:\n",
        "    word embedding + positional embedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        # angles = 1/10000^{2i/d_model}\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        # position/10000^{2i/d_model}\n",
        "        return position * angles\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        # angle_rads size is [position, d_model]\n",
        "        angle_rads = self.get_angles(\n",
        "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis], # [position, 1]\n",
        "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :], # [1, d_model]\n",
        "            d_model=d_model)\n",
        "\n",
        "        # 1.행렬의 모든 행을 선택하라. 2. 0::2는 0번째 열부터 시작하여 한 열마다 한 열을 선택함을 나타냅니다.\n",
        "        # 1.选择矩阵中的所有行，2. 0::2 表示从第0列开始，每隔一列选择一列\n",
        "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "        # 1.행렬의 모든 행을 선택하라. 2. 1::2는 1번째 열부터 시작하여 한 열마다 한 열을 선택함을 나타냅니다.\n",
        "        # 1.选择矩阵中的所有行，2. 1::2 表示从第1列开始，每隔一列选择一列\n",
        "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        angle_rads = np.zeros(angle_rads.shape)\n",
        "        angle_rads[:, 0::2] = sines\n",
        "        angle_rads[:, 1::2] = cosines\n",
        "\n",
        "        # angle_rads를 Tensor로 변환\n",
        "        # 将angle_rads转换为Tensor\n",
        "        pos_encoding = tf.constant(angle_rads)\n",
        "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "        print(pos_encoding.shape)\n",
        "        return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df00a5e6",
      "metadata": {
        "id": "df00a5e6"
      },
      "source": [
        "## MultiHead Attention\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8ab5866",
      "metadata": {
        "id": "b8ab5866"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    '''\n",
        "    d_model: 각 헤드의 주의력이 나타내는 차원의 총합입니다.\n",
        "    num_heads: 병렬 주의 계층의 수입니다.\n",
        "    depth: d_model을 num_heads로 나눈 것과 같은 각 헤드의 차원입니다.\n",
        "    query_dense, key_dense 및 value_dense: 각각 쿼리(Q), 키(K) 및 값(V) 표시를 생성하는 데 사용되는 전체 연결 계층입니다.\n",
        "\n",
        "    d_model：是每个头的注意力表示的维度的总和。\n",
        "    num_heads：是并行注意力层的数量。\n",
        "    depth：是每个头的维度，等于d_model除以num_heads。\n",
        "    query_dense、key_dense和value_dense：分别是用于创建查询（Q）、键（K）和值（V）表示的全连接层。\n",
        "    '''\n",
        "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        # d_model을 num_heads로 나눈 값.\n",
        "        # 논문 기준 : 64\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
        "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "        # WO에 해당하는 밀집층 정의\n",
        "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    # num_heads 개수만큼 q, k, v를 split하는 함수\n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        \"\"\"\n",
        "        마지막 차원을 (num_heads, depth)로 분할합니다.\n",
        "        모양 바꾸기 (batch_size, num_heads, seq_len, depth)\n",
        "        分拆最后一个维度到 (num_heads, depth).\n",
        "        转置结果使得形状为 (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        inputs = tf.reshape(\n",
        "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
        "        # q : (batch_size, seq_len, d_model)\n",
        "        # k : (batch_size, seq_len, d_model)\n",
        "        # v : (batch_size, seq_len, d_model)\n",
        "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        # 2. 헤드 나누기\n",
        "        # depth = d_model/num_heads\n",
        "        # q : (batch_size, num_heads, seq_len_q, depth)\n",
        "        # k : (batch_size, num_heads, seq_len_k, depth)\n",
        "        # v : (batch_size, num_heads, seq_len_v, depth)\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
        "        # (batch_size, num_heads, seq_len_q, depth)\n",
        "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
        "        # (batch_size, seq_len_q, num_heads, depth)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # 4. 헤드 연결(concatenate)하기\n",
        "        # (batch_size, seq_len_q, d_model)\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))\n",
        "\n",
        "        # 5. WO에 해당하는 밀집층 지나기\n",
        "        # (batch_size, seq_len_q, d_model)\n",
        "        outputs = self.dense(concat_attention)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "164bb3d8",
      "metadata": {
        "id": "164bb3d8"
      },
      "source": [
        "![0cf7276b8e0644559c74fdb0bcbe8aac.gif](attachment:0cf7276b8e0644559c74fdb0bcbe8aac.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d72f588c",
      "metadata": {
        "id": "d72f588c"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "![image-2.png](attachment:image-2.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef5e2696",
      "metadata": {
        "id": "ef5e2696"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    \"\"\"\n",
        "    주의력 가중치를 계산하다.\n",
        "    q, k, v는 반드시 일치하는 사전 차원을 가져야 합니다.\n",
        "    k, v에는 seq_len_k = seq_len_v와 같은 일치하는 마지막 두 번째 차원이 있어야 합니다.\n",
        "    mask는 그 종류(채우기 또는 전향)에 따라 모양이 다르지만,\n",
        "    그러나 mask는 합을 맞추기 위해 방송 변환을 할 수 있어야 합니다.\n",
        "\n",
        "    parameter:\n",
        "        q: 요청한 모양 == (..., .., seq_len_q, depth)\n",
        "        k: 주 키 모양 == (..., .., seq_len_k, depth)\n",
        "        v: 수치의 모양 == (..., .., seq_len_v, depth_v)\n",
        "        mask: 모양을 변환할 수 있는 Float 텐서\n",
        "              (..., .., seq_len_q, seq_len_k)。기본값은 None입니다.\n",
        "\n",
        "    return:\n",
        "        출력, 주의력 가중치\n",
        "\n",
        "         计算注意力权重。\n",
        "    q, k, v 必须具有匹配的前置维度。\n",
        "    k, v 必须有匹配的倒数第二个维度，例如：seq_len_k = seq_len_v。\n",
        "    虽然 mask 根据其类型（填充或前瞻）有不同的形状，\n",
        "    但是 mask 必须能进行广播转换以便求和。\n",
        "\n",
        "    parameter:\n",
        "        q: 请求的形状 == (..., seq_len_q, depth)\n",
        "        k: 主键的形状 == (..., seq_len_k, depth)\n",
        "        v: 数值的形状 == (..., seq_len_v, depth_v)\n",
        "        mask: Float 张量，其形状能转换成\n",
        "              (..., seq_len_q, seq_len_k)。默认为None。\n",
        "\n",
        "    return:\n",
        "        输出，注意力权重\n",
        "    \"\"\"\n",
        "\n",
        "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
        "\n",
        "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "    # 스케일링\n",
        "    # dk의 루트값으로 나눠준다.\n",
        "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
        "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
        "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
        "    # softmax 在最后一个轴（seq_len_k）上归一化，因此分数   （对注意力矩阵每一行归一化，\n",
        "    # 则每个字的注意力向量一行，就是与其余字的相关程度，和为1）\n",
        "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "\n",
        "    return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c37ca532",
      "metadata": {
        "id": "c37ca532"
      },
      "source": [
        "## Encoder\n",
        "<img src=\"https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-12.png\" width=256 height=256 />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d71f15",
      "metadata": {
        "id": "f2d71f15"
      },
      "outputs": [],
      "source": [
        "def encoder(vocab_size, num_layers, dff, d_model, num_heads, dropout, name=\"encoder\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "    # 인코더는 패딩 마스크 사용\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    # 포지셔널 인코딩 + 드롭아웃\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    # 인코더를 num_layers개 쌓기\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "                                dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
        "                               )([outputs, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a021da2",
      "metadata": {
        "id": "3a021da2"
      },
      "outputs": [],
      "source": [
        "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "    # 인코더는 패딩 마스크 사용\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
        "    attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "          'mask': padding_mask # 패딩 마스크 사용\n",
        "      })\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
        "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea41c91c",
      "metadata": {
        "id": "ea41c91c"
      },
      "source": [
        "## Decoder\n",
        "[image.png]\n",
        "<img src=\"attachment:image.png\" width=512 height=512/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70551f33",
      "metadata": {
        "id": "70551f33"
      },
      "outputs": [],
      "source": [
        "def decoder(vocab_size, num_layers, dff,\n",
        "            d_model, num_heads, dropout,\n",
        "            name='decoder'):\n",
        "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "\n",
        "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    # 포지셔널 인코딩 + 드롭아웃\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    # 디코더를 num_layers개 쌓기\n",
        "    for i in range(num_layers):\n",
        "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
        "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7931c5f3",
      "metadata": {
        "id": "7931c5f3"
      },
      "outputs": [],
      "source": [
        "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "\n",
        "    # 룩어헤드 마스크(첫번째 서브층)\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "\n",
        "    # 패딩 마스크(두번째 서브층)\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
        "    attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
        "      })\n",
        "\n",
        "    # 잔차 연결과 층 정규화\n",
        "    attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
        "    attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
        "          'mask': padding_mask # 패딩 마스크\n",
        "      })\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "    attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
        "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "badde996",
      "metadata": {
        "id": "badde996"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "![image-2.png](attachment:image-2.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "976bc4fd",
      "metadata": {
        "id": "976bc4fd"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(x):\n",
        "    # x에 0이 포함되어 있는지 여부 판단\n",
        "    # 判断x中是否包含0\n",
        "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "    # (batch_size, 1, 1, key의 문장 길이)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9978506d",
      "metadata": {
        "id": "9978506d"
      },
      "outputs": [],
      "source": [
        "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
        "def create_look_ahead_mask(x):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
        "\n",
        "    # 전향 마스크와 채우기 마스크를 결합하여 주의력을 계산할 때 모델이 미래의 단어와 채우기 단어를 무시합니다.\n",
        "    # 前瞻掩码和填充掩码结合起来，这样在计算注意力时，模型将忽略未来的词汇和填充的词汇\n",
        "    return tf.maximum(look_ahead_mask, padding_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d373c15",
      "metadata": {
        "id": "7d373c15"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size, num_layers, dff, d_model, num_heads, dropout, name=\"transformer\"):\n",
        "\n",
        "    # 인코더의 입력\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "    # 디코더의 입력\n",
        "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "    # 인코더의 패딩 마스크\n",
        "    enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
        "    look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "    # 디코더의 패딩 마스크(두번째 서브층)\n",
        "    dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
        "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
        "\n",
        "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
        "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "    # 다음 단어 예측을 위한 출력층\n",
        "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b81f88",
      "metadata": {
        "id": "a4b81f88"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼 파라미터\n",
        "D_MODEL = 256\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 8\n",
        "DFF = 512\n",
        "DROPOUT = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68e0da4a",
      "metadata": {
        "id": "68e0da4a",
        "outputId": "b28df129-e41d-4765-ab9d-25f0d935d5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 8180, 256)\n",
            "(1, 8180, 256)\n"
          ]
        }
      ],
      "source": [
        "model = transformer(vocab_size=VOCAB_SIZE,\n",
        "                    num_layers=NUM_LAYERS,\n",
        "                    dff=DFF,\n",
        "                    d_model=D_MODEL,\n",
        "                    num_heads=NUM_HEADS,\n",
        "                    dropout=DROPOUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "061fed68",
      "metadata": {
        "id": "061fed68"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7493c7d5",
      "metadata": {
        "id": "7493c7d5"
      },
      "outputs": [],
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "    loss = tf.multiply(loss, mask)\n",
        "\n",
        "    return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "804a53fd",
      "metadata": {
        "id": "804a53fd"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
        "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "239cf3fb",
      "metadata": {
        "scrolled": true,
        "id": "239cf3fb",
        "outputId": "de65e97f-b92c-43e1-ae24-7d055d30c4a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 03:19:06.733294: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2023-11-28 03:19:06.780682: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2100000000 Hz\n",
            "2023-11-28 03:19:07.860264: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  2/185 [..............................] - ETA: 17s - loss: 1.5502 - accuracy: 0.0000e+00  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 03:19:09.273794: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2023-11-28 03:19:09.273859: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "185/185 [==============================] - 20s 74ms/step - loss: 1.4460 - accuracy: 0.0236\n",
            "Epoch 2/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 1.1751 - accuracy: 0.0495\n",
            "Epoch 3/150\n",
            "185/185 [==============================] - 14s 73ms/step - loss: 1.0025 - accuracy: 0.0506\n",
            "Epoch 4/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.9281 - accuracy: 0.0544\n",
            "Epoch 5/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.8708 - accuracy: 0.0576\n",
            "Epoch 6/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.8106 - accuracy: 0.0618\n",
            "Epoch 7/150\n",
            "185/185 [==============================] - 13s 73ms/step - loss: 0.7444 - accuracy: 0.0678\n",
            "Epoch 8/150\n",
            "185/185 [==============================] - 12s 66ms/step - loss: 0.6715 - accuracy: 0.0754\n",
            "Epoch 9/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.5925 - accuracy: 0.0841\n",
            "Epoch 10/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.5103 - accuracy: 0.0935\n",
            "Epoch 11/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.4284 - accuracy: 0.1037\n",
            "Epoch 12/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.3470 - accuracy: 0.1146\n",
            "Epoch 13/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.2734 - accuracy: 0.1256\n",
            "Epoch 14/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.2070 - accuracy: 0.1360\n",
            "Epoch 15/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.1526 - accuracy: 0.1452\n",
            "Epoch 16/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.1101 - accuracy: 0.1532\n",
            "Epoch 17/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0802 - accuracy: 0.1585\n",
            "Epoch 18/150\n",
            "185/185 [==============================] - 14s 73ms/step - loss: 0.0613 - accuracy: 0.1618\n",
            "Epoch 19/150\n",
            "185/185 [==============================] - 13s 73ms/step - loss: 0.0510 - accuracy: 0.1636\n",
            "Epoch 20/150\n",
            "185/185 [==============================] - 13s 73ms/step - loss: 0.0454 - accuracy: 0.1645\n",
            "Epoch 21/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0430 - accuracy: 0.1646\n",
            "Epoch 22/150\n",
            "185/185 [==============================] - 13s 73ms/step - loss: 0.0399 - accuracy: 0.1653\n",
            "Epoch 23/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0365 - accuracy: 0.1660\n",
            "Epoch 24/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0316 - accuracy: 0.1674\n",
            "Epoch 25/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0281 - accuracy: 0.1682\n",
            "Epoch 26/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0251 - accuracy: 0.1688\n",
            "Epoch 27/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0218 - accuracy: 0.1696\n",
            "Epoch 28/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0204 - accuracy: 0.1700\n",
            "Epoch 29/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0187 - accuracy: 0.1705\n",
            "Epoch 30/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0167 - accuracy: 0.1709\n",
            "Epoch 31/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0152 - accuracy: 0.1714\n",
            "Epoch 32/150\n",
            "185/185 [==============================] - 13s 73ms/step - loss: 0.0141 - accuracy: 0.1716\n",
            "Epoch 33/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0135 - accuracy: 0.1718\n",
            "Epoch 34/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0121 - accuracy: 0.1721\n",
            "Epoch 35/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0118 - accuracy: 0.1723\n",
            "Epoch 36/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0109 - accuracy: 0.1725\n",
            "Epoch 37/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0100 - accuracy: 0.1727\n",
            "Epoch 38/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0100 - accuracy: 0.1726\n",
            "Epoch 39/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0089 - accuracy: 0.1730\n",
            "Epoch 40/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0086 - accuracy: 0.1731\n",
            "Epoch 41/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0083 - accuracy: 0.1731\n",
            "Epoch 42/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0078 - accuracy: 0.1732\n",
            "Epoch 43/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0076 - accuracy: 0.1732\n",
            "Epoch 44/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0072 - accuracy: 0.1734\n",
            "Epoch 45/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0069 - accuracy: 0.1734\n",
            "Epoch 46/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0066 - accuracy: 0.1735\n",
            "Epoch 47/150\n",
            "185/185 [==============================] - 13s 68ms/step - loss: 0.0064 - accuracy: 0.1735\n",
            "Epoch 48/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0060 - accuracy: 0.1736\n",
            "Epoch 49/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0060 - accuracy: 0.1737\n",
            "Epoch 50/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0055 - accuracy: 0.1737\n",
            "Epoch 51/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0060 - accuracy: 0.1736\n",
            "Epoch 52/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0051 - accuracy: 0.1739\n",
            "Epoch 53/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0050 - accuracy: 0.1738\n",
            "Epoch 54/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0048 - accuracy: 0.1739\n",
            "Epoch 55/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0048 - accuracy: 0.1739\n",
            "Epoch 56/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0049 - accuracy: 0.1739\n",
            "Epoch 57/150\n",
            "185/185 [==============================] - 13s 70ms/step - loss: 0.0048 - accuracy: 0.1739\n",
            "Epoch 58/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0044 - accuracy: 0.1740\n",
            "Epoch 59/150\n",
            "185/185 [==============================] - 13s 73ms/step - loss: 0.0043 - accuracy: 0.1741\n",
            "Epoch 60/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0044 - accuracy: 0.1740\n",
            "Epoch 61/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0041 - accuracy: 0.1741\n",
            "Epoch 62/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0040 - accuracy: 0.1741\n",
            "Epoch 63/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0039 - accuracy: 0.1741\n",
            "Epoch 64/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0037 - accuracy: 0.1741\n",
            "Epoch 65/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0038 - accuracy: 0.1741\n",
            "Epoch 66/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0037 - accuracy: 0.1741\n",
            "Epoch 67/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0038 - accuracy: 0.1741\n",
            "Epoch 68/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0038 - accuracy: 0.1741\n",
            "Epoch 69/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0033 - accuracy: 0.1742\n",
            "Epoch 70/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0033 - accuracy: 0.1742\n",
            "Epoch 71/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0035 - accuracy: 0.1742\n",
            "Epoch 72/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0033 - accuracy: 0.1742\n",
            "Epoch 73/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0032 - accuracy: 0.1742\n",
            "Epoch 74/150\n",
            "185/185 [==============================] - 13s 73ms/step - loss: 0.0031 - accuracy: 0.1743\n",
            "Epoch 75/150\n",
            "185/185 [==============================] - 14s 73ms/step - loss: 0.0031 - accuracy: 0.1743\n",
            "Epoch 76/150\n",
            "185/185 [==============================] - 13s 73ms/step - loss: 0.0029 - accuracy: 0.1743\n",
            "Epoch 77/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0029 - accuracy: 0.1743\n",
            "Epoch 78/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0031 - accuracy: 0.1742\n",
            "Epoch 79/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0028 - accuracy: 0.1743\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 80/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0029 - accuracy: 0.1743\n",
            "Epoch 81/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0028 - accuracy: 0.1743\n",
            "Epoch 82/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0026 - accuracy: 0.1744\n",
            "Epoch 83/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0026 - accuracy: 0.1744\n",
            "Epoch 84/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0026 - accuracy: 0.1743\n",
            "Epoch 85/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0028 - accuracy: 0.1743\n",
            "Epoch 86/150\n",
            "185/185 [==============================] - 12s 64ms/step - loss: 0.0025 - accuracy: 0.1744\n",
            "Epoch 87/150\n",
            "185/185 [==============================] - 11s 60ms/step - loss: 0.0024 - accuracy: 0.1744\n",
            "Epoch 88/150\n",
            "185/185 [==============================] - 11s 60ms/step - loss: 0.0024 - accuracy: 0.1744\n",
            "Epoch 89/150\n",
            "185/185 [==============================] - 11s 61ms/step - loss: 0.0025 - accuracy: 0.1743\n",
            "Epoch 90/150\n",
            "185/185 [==============================] - 11s 60ms/step - loss: 0.0025 - accuracy: 0.1744\n",
            "Epoch 91/150\n",
            "185/185 [==============================] - 11s 61ms/step - loss: 0.0023 - accuracy: 0.1744\n",
            "Epoch 92/150\n",
            "185/185 [==============================] - 11s 62ms/step - loss: 0.0020 - accuracy: 0.1744\n",
            "Epoch 93/150\n",
            "185/185 [==============================] - 11s 61ms/step - loss: 0.0024 - accuracy: 0.1744\n",
            "Epoch 94/150\n",
            "185/185 [==============================] - 11s 59ms/step - loss: 0.0021 - accuracy: 0.1744\n",
            "Epoch 95/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0023 - accuracy: 0.1744\n",
            "Epoch 96/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0023 - accuracy: 0.1744\n",
            "Epoch 97/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0021 - accuracy: 0.1744\n",
            "Epoch 98/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0023 - accuracy: 0.1744\n",
            "Epoch 99/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0020 - accuracy: 0.1744\n",
            "Epoch 100/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0019 - accuracy: 0.1745\n",
            "Epoch 101/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0018 - accuracy: 0.1744\n",
            "Epoch 102/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0021 - accuracy: 0.1744\n",
            "Epoch 103/150\n",
            "185/185 [==============================] - 13s 73ms/step - loss: 0.0019 - accuracy: 0.1744\n",
            "Epoch 104/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0018 - accuracy: 0.1745\n",
            "Epoch 105/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0019 - accuracy: 0.1744\n",
            "Epoch 106/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0017 - accuracy: 0.1745\n",
            "Epoch 107/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0018 - accuracy: 0.1745\n",
            "Epoch 108/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0019 - accuracy: 0.1744\n",
            "Epoch 109/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0018 - accuracy: 0.1744\n",
            "Epoch 110/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0019 - accuracy: 0.1744\n",
            "Epoch 111/150\n",
            "185/185 [==============================] - 13s 70ms/step - loss: 0.0017 - accuracy: 0.1745\n",
            "Epoch 112/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0018 - accuracy: 0.1745\n",
            "Epoch 113/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0016 - accuracy: 0.1745\n",
            "Epoch 114/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0016 - accuracy: 0.1745\n",
            "Epoch 115/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0018 - accuracy: 0.1745\n",
            "Epoch 116/150\n",
            "185/185 [==============================] - 13s 73ms/step - loss: 0.0016 - accuracy: 0.1745\n",
            "Epoch 117/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0017 - accuracy: 0.1745\n",
            "Epoch 118/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0015 - accuracy: 0.1745\n",
            "Epoch 119/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0016 - accuracy: 0.1745\n",
            "Epoch 120/150\n",
            "185/185 [==============================] - 14s 73ms/step - loss: 0.0014 - accuracy: 0.1745\n",
            "Epoch 121/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0016 - accuracy: 0.1745\n",
            "Epoch 122/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0015 - accuracy: 0.1745\n",
            "Epoch 123/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0015 - accuracy: 0.1745\n",
            "Epoch 124/150\n",
            "185/185 [==============================] - 13s 73ms/step - loss: 0.0015 - accuracy: 0.1745\n",
            "Epoch 125/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0016 - accuracy: 0.1745\n",
            "Epoch 126/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0016 - accuracy: 0.1745\n",
            "Epoch 127/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0015 - accuracy: 0.1745\n",
            "Epoch 128/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0014 - accuracy: 0.1745\n",
            "Epoch 129/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0014 - accuracy: 0.1745\n",
            "Epoch 130/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0014 - accuracy: 0.1745\n",
            "Epoch 131/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0013 - accuracy: 0.1745\n",
            "Epoch 132/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0015 - accuracy: 0.1745\n",
            "Epoch 133/150\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0014 - accuracy: 0.1745\n",
            "Epoch 134/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0013 - accuracy: 0.1745\n",
            "Epoch 135/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0014 - accuracy: 0.1745\n",
            "Epoch 136/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0014 - accuracy: 0.1745\n",
            "Epoch 137/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0013 - accuracy: 0.1745\n",
            "Epoch 138/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0013 - accuracy: 0.1745\n",
            "Epoch 139/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0014 - accuracy: 0.1745\n",
            "Epoch 140/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0015 - accuracy: 0.1745\n",
            "Epoch 141/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0014 - accuracy: 0.1745\n",
            "Epoch 142/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0014 - accuracy: 0.1745\n",
            "Epoch 143/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0013 - accuracy: 0.1745\n",
            "Epoch 144/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0014 - accuracy: 0.1745\n",
            "Epoch 145/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0013 - accuracy: 0.1745\n",
            "Epoch 146/150\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0012 - accuracy: 0.1745\n",
            "Epoch 147/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0012 - accuracy: 0.1745\n",
            "Epoch 148/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0012 - accuracy: 0.1745\n",
            "Epoch 149/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0012 - accuracy: 0.1745\n",
            "Epoch 150/150\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0014 - accuracy: 0.1745\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8eab0b5fd0>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EPOCHS = 150\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "821f05fe",
      "metadata": {
        "id": "821f05fe"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    # 단어와 구두점 사이에 공백 추가.\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d5e7c48",
      "metadata": {
        "id": "0d5e7c48"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "    sentence = preprocess_sentence(sentence) # 입력 문장에 대한 전처리 수행\n",
        "\n",
        "    # 입력 문장에 시작 토큰과 종료 토큰을 추가\n",
        "    sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "    output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "    # 디코더의 예측\n",
        "    for i in range(MAX_LENGTH):\n",
        "        predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "        predictions = predictions[:, -1:, :] # 현재 시점의 예측 단어를 받아옴\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
        "        if tf.equal(predicted_id, END_TOKEN[0]): break\n",
        "\n",
        "        # 현재 시점의 예측 단어를 output에 연결되고 다음 루프에서 디코더의 입력이 됨\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0) # 단어 예측이 모두 끝났다면 output을 리턴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7c0a40",
      "metadata": {
        "id": "6c7c0a40"
      },
      "outputs": [],
      "source": [
        "def predict(sentence):\n",
        "    prediction = evaluate(sentence)\n",
        "\n",
        "    # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n",
        "    # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩\n",
        "    predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "    return predicted_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb95bd0b",
      "metadata": {
        "id": "bb95bd0b",
        "outputId": "c102a05a-ea1d-4108-ae14-f313a7682c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: 영화 볼래?\n",
            "Output: 솔직한 마음으로 다가가보세요 .\n"
          ]
        }
      ],
      "source": [
        "output = predict(\"영화 볼래?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}